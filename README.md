# ActiViz

**ActiViz** is an interactive web application that visualizes how different neural network activation functions affect training, convergence, and optimization in real time. Inspired by educational tools like TensorFlow Playground, ActiViz allows users to experiment with various activation functions, learning rates, and architectures through a beautiful and responsive UI.

## âœ¨ Features

* ðŸŽ› **Dynamic activation function selection** (ReLU, Sigmoid, Tanh, Linear)
* ðŸ“‰ **Live loss curve plotting** over epochs
* ðŸ“Š **Interactive scatter plot of input features and labels**
* âš™ï¸ **Adjustable hyperparameters** like learning rate and epochs

## ðŸ›  Tech Stack

| Layer         | Technology                        |
| ------------- | --------------------------------- |
| Frontend      | React, TypeScript, Tailwind CSS   |
| Visualization | Recharts, Chart.js, Framer Motion |
| ML Engine     | TensorFlow.js                    |
| Build Tool    | Vite                              |

## ðŸ— Project Structure

```
src/
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ ControlPanel.tsx      # UI for selecting activations, learning rate, epochs
â”‚   â”œâ”€â”€ LossChart.tsx         # Line chart showing loss over time
â”‚   â””â”€â”€ InputScatterPlot.tsx  # Scatter plot of synthetic input data
â”œâ”€â”€ logic/
â”‚   â””â”€â”€ model.ts              # TensorFlow.js model definition & training logic
â”œâ”€â”€ App.tsx                   # Main React app
â”œâ”€â”€ index.css                 # Global styles, theming, responsiveness
â””â”€â”€ main.tsx                  # App entry point
```

## ðŸš€ Getting Started

### Prerequisites

* Node.js â‰¥ 16
* npm

### Setup

```bash
# Clone the repo
git clone https://github.com/bisbist/ActiViz.git
cd activiz

# Install dependencies
npm install

# Run development server
npm run dev
```

Visit âž¡ï¸ **[http://localhost:5173](http://localhost:5173)**

## ðŸ§ª How It Works

* **Synthetic data**: Generates 2D random points; labels are `1` if xâ‚ + xâ‚‚ > 1, else `0`.
* **Model**: Feedforward neural network with 3 hidden layers (64 units each) and user-selected activation function.
* **Output**: Sigmoid layer for binary classification.
* **Visualization**: Shows both feature space (scatter plot) and training performance (loss chart).

## ðŸ”® Planned Enhancements

* Add gradient and weight visualizations layer-wise.
* Enable multiple dataset selection.
* Export training animations as GIFs.
* Compare multiple optimizers (SGD, Adam, RMSProp).
* Provide explainable AI (XAI) overlays.

## ðŸŒŸ Acknowledgments

* Inspiration: TensorFlow Playground
